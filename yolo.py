# -*- coding: utf-8 -*-
"""
YOLOv5 åµæ¸¬ + è£åˆ‡
æµç¨‹ï¼š
  1) ç”¨ tr3.pt åˆ¤æ–·ç™¼ç¥¨é¡å‹ï¼špc / op / mi
  2) ç”¨å°æ‡‰çš„ pc.pt / op.pt / mi.pt åµæ¸¬æ¬„ä½æ¡†ï¼šnum/date/sun/cash
  3) ä¾æ¡†è£åˆ‡å°åœ–ï¼Œäº¤ç”± ocr_utils åš OCR + è¦å‰‡æ¸…æ´—
  4) å›å‚³æ¬„ä½æ–‡å­—èˆ‡è£åˆ‡å°åœ–è·¯å¾‘ï¼ˆå« web_pathï¼Œå‰ç«¯å¯ç›´æ¥ <img src=...>ï¼‰

éœ€è¦ï¼štorch, opencv-python, pytesseract, pdf2image
"""
from typing import Any, Dict, Optional, List, Tuple
import os
import uuid
from yocr.ocr_utils import ocr_fields_from_crops, fullpage_anchor_ocr
# ä¾è³´
try:
    import torch
except Exception:
    torch = None

try:
    import cv2
except Exception:
    cv2 = None


# ---------- æ¨¡å‹è·¯å¾‘ ----------
def _env_or_default(name: str, filename: str) -> str:
    """
    å…ˆè®€ç’°å¢ƒè®Šæ•¸ï¼Œå¦‚æœæ²’æœ‰å°±ç”¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ weights è³‡æ–™å¤¾ã€‚
    """
    p = os.environ.get(name, "")
    if p and os.path.isfile(p):
        return p

    # fallbackï¼šå°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ weights
    here = os.path.dirname(os.path.abspath(__file__))
    root = os.path.dirname(here)  # b2b_st å°ˆæ¡ˆæ ¹
    weights_dir = os.path.join(root, "weights")
    alt = os.path.join(weights_dir, filename)
    return alt if os.path.isfile(alt) else filename


MODEL_PATHS = {
    "tr3": _env_or_default("YOLO_TR3", "tr3.pt"),
    "pc":  _env_or_default("YOLO_PC",  "pc.pt"),
    "op":  _env_or_default("YOLO_OP",  "op.pt"),
    "mi":  _env_or_default("YOLO_MI",  "mi.pt"),
}

DEFAULT_KEY_ORDER = ["num", "date", "sun", "cash"]

# å•Ÿå‹•æ™‚å°å‡ºè·¯å¾‘ç¢ºèª
print("[YOLO MODEL PATHS]", MODEL_PATHS)


# ---------- å°å·¥å…· ----------
def _load_bgr(img_or_path: Any):
    if cv2 is None:
        return None
    if isinstance(img_or_path, (str, bytes)):
        return cv2.imread(img_or_path)
    if getattr(img_or_path, "shape", None) is not None:
        return img_or_path
    return None


def _ensure_dir(d: str):
    if d and not os.path.isdir(d):
        os.makedirs(d, exist_ok=True)


def _load_yolo_model(model_path: str):
    if torch is None:
        raise RuntimeError("PyTorch æœªå®‰è£ï¼Œç„¡æ³•è¼‰å…¥ YOLOv5 æ¨¡å‹ã€‚")
    if not os.path.isfile(model_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° YOLO æ¨¡å‹ï¼š{model_path}")
    # å…ˆè©¦ localï¼Œæ²’æœ‰å†ç”¨ githubï¼ˆéœ€è¦ Git/å¯é€£å¤–ï¼‰
    try:
        return torch.hub.load("ultralytics/yolov5", "custom",
                              path=model_path, source="local", force_reload=False)
    except Exception:
        return torch.hub.load("ultralytics/yolov5", "custom",
                              path=model_path, source="github", force_reload=False)


def _map_class_to_key(model) -> Dict[int, str]:
    names = getattr(model, "names", None)
    mapping: Dict[int, str] = {}

    def norm_to_key(n_lower: str) -> str:
        if any(k in n_lower for k in ("num", "number", "invno", "invoice number", "invoice_number", "ç™¼ç¥¨è™Ÿç¢¼")):
            return "num"
        if any(k in n_lower for k in ("date", "æ—¥æœŸ", "é–‹ç«‹æ—¥æœŸ")):
            return "date"
        if any(k in n_lower for k in ("sun", "vat", "çµ±ä¸€ç·¨è™Ÿ")):
            return "sun"
        if any(k in n_lower for k in ("cash", "amount", "price", "total", "äº¤æ˜“é‡‘é¡", "é‡‘é¡")):
            return "cash"
        if n_lower in ("pc", "op", "mi"):
            return n_lower
        return ""

    if isinstance(names, (list, tuple)):
        for i, n in enumerate(names):
            k = norm_to_key(str(n).lower())
            if k: mapping[i] = k
    elif isinstance(names, dict):
        for i, n in names.items():
            k = norm_to_key(str(n).lower())
            if k: mapping[int(i)] = k

    if not mapping:
        mapping = {i: DEFAULT_KEY_ORDER[i] for i in range(min(4, len(DEFAULT_KEY_ORDER)))}
    return mapping


def _choose_invoice_type(det, mapping_from_names: Dict[int, str]) -> str:
    import torch as _torch
    if det is None or det.shape[0] == 0:
        return "pc"
    confs = det[:, 4]
    idx = int(_torch.argmax(confs).item())
    cls_idx = int(det[idx, -1].item())
    name = mapping_from_names.get(cls_idx, "")
    if name in ("pc", "op", "mi"):
        return name
    fallback = ["pc", "op", "mi"]
    return fallback[cls_idx] if cls_idx < len(fallback) else "pc"

def _pad_box(x1, y1, x2, y2, W, H, l=0.0, t=0.0, r=0.0, b=0.0):
    """ä¾æ¯”ä¾‹å°æ¡†åšå·¦å³ä¸Šä¸‹ paddingï¼›æ¯”ä¾‹æ˜¯ç›¸å°æ–¼æ¡†å¯¬/é«˜ã€‚"""
    bw, bh = (x2 - x1), (y2 - y1)
    x1 = max(0, int(x1 - l * bw))
    y1 = max(0, int(y1 - t * bh))
    x2 = min(W - 1, int(x2 + r * bw))
    y2 = min(H - 1, int(y2 + b * bh))
    return x1, y1, x2, y2

def _crop(img_bgr, box: Tuple[int, int, int, int], out_path: str) -> bool:
    if cv2 is None or img_bgr is None or box is None:
        return False
    x1, y1, x2, y2 = box
    h, w = img_bgr.shape[:2]
    x1 = max(0, min(int(x1), w - 1)); x2 = max(0, min(int(x2), w - 1))
    y1 = max(0, min(int(y1), h - 1)); y2 = max(0, min(int(y2), h - 1))
    if x2 <= x1 or y2 <= y1:
        return False
    crop = img_bgr[y1:y2, x1:x2].copy()
    return cv2.imwrite(out_path, crop)


# ---------- ä¸»æµç¨‹ ----------
def detect_and_ocr(img_or_path: Any, crops_dir: Optional[str] = None, inv_type: str = "auto", **kwargs) -> Dict[str, Any]:
    """
    :param img_or_path: å½±åƒè·¯å¾‘æˆ– numpy array(BGR)
    :param crops_dir:   è£åˆ‡è¼¸å‡ºè³‡æ–™å¤¾
    :param inv_type:    'auto' / 'pc' / 'op' / 'mi'
    :return: { type, num, date, sun, cash, crops: [{key,path,web_path}, ...] }
    """
    img_bgr = _load_bgr(img_or_path)
    if img_bgr is None:
        raise RuntimeError("è¼‰å…¥åœ–ç‰‡å¤±æ•—ï¼ˆOpenCV ç„¡æ³•è®€å–ï¼‰ã€‚")

    if crops_dir:
        _ensure_dir(crops_dir)
    else:
        here = os.path.dirname(os.path.abspath(__file__))
        crops_dir = os.path.join(here, "..", "uploads", "cropped")
        _ensure_dir(crops_dir)

    base_name = os.path.splitext(os.path.basename(str(img_or_path)))[0]
    nonce = uuid.uuid4().hex[:6]

    # 1) åˆ¤æ–·ç¥¨ç¨®
    tr3 = _load_yolo_model(MODEL_PATHS["tr3"])
    class_map = _map_class_to_key(tr3)
    with torch.no_grad():
        # æ”¾å¤§åˆ° 960 æ¯”é è¨­ 640 æ›´ç©©
        try:
            tr3.conf = float(os.environ.get("YOLO_CONF", 0.15))
            tr3.iou  = float(os.environ.get("YOLO_IOU", 0.45))
        except Exception:
            pass
        res_tr3 = tr3(img_bgr, size=960)
    det_tr3 = res_tr3.xyxy[0]
    inv = _choose_invoice_type(det_tr3, class_map) if inv_type == "auto" else inv_type.lower()
    if inv not in ("pc", "op", "mi"):
        inv = "pc"

    # 2) æ¬„ä½åµæ¸¬
    model_inv = _load_yolo_model(MODEL_PATHS[inv])
    field_map = _map_class_to_key(model_inv)
    with torch.no_grad():
        # â†“ é™ä¿¡å¿ƒé–€æª» + æ”¾å¤§è¼¸å…¥å°ºå¯¸
        try:
            model_inv.conf = float(os.environ.get("YOLO_CONF", 0.20))  # ä½ åŸæœ¬å°±æœ‰ 0.20ï¼Œå¯ä¿ç•™
            model_inv.iou  = float(os.environ.get("YOLO_IOU", 0.45))
        except Exception:
            pass
        res_fields = model_inv(img_bgr, size=1280)
    det = res_fields.xyxy[0]

    # 3) è£åˆ‡
    crops: List[Dict[str, str]] = []
    H, W = img_bgr.shape[:2]
    for row in det.tolist():
        x1, y1, x2, y2, conf, cls = row
        key = field_map.get(int(cls))
        if key not in ("num", "date", "sun", "cash"):
            continue

        # ğŸ‘‰ é€™è£¡æ–°å¢
        if inv == "op" and key == "num":
            H, W = img_bgr.shape[:2]
            x1, y1, x2, y2 = _pad_box(int(x1), int(y1), int(x2), int(y2),
                                       W, H, l=0.05, t=0.02, r=0.45, b=0.02)
            
        if inv == "pc" and key in ("num", "cash"):
            x1, y1, x2, y2 = _pad_box(
                int(x1), int(y1), int(x2), int(y2), W, H,
                l=0.05, t=0.02, r=(0.30 if key == "num" else 0.20), b=0.02
            )

        out_file = f"{base_name}_{nonce}_{key}.jpg"
        out_path = os.path.join(crops_dir, out_file)
        if _crop(img_bgr, (int(x1), int(y1), int(x2), int(y2)), out_path):
            crops.append({"key": key, "path": out_file})

    # 4) OCR + æ¸…æ´—ï¼ˆå°åœ–ï¼‰
    fields = ocr_fields_from_crops({c["key"]: os.path.join(crops_dir, c["path"]) for c in crops}, inv)

    # 4.1) å‚™æ´ï¼šå°åœ–æŠ“ä¸åˆ°å°±ç”¨æ•´é éŒ¨é»è£œ
    missing = [k for k in ("num","date","sun","cash") if not fields.get(k)]
    need_fallback = (
        (inv in ("mi", "op") and (len(missing) >= 2 or "sun" in missing))
        or (inv == "pc" and any(k in missing for k in ("num", "cash", "date")))
    )
    if need_fallback:
        fb = fullpage_anchor_ocr(img_bgr, inv)
        for k in missing:
            if fb.get(k):
                fields[k] = fb[k]

    # 5) è£ä¸Šå‰ç«¯å¯ç”¨ç¶²å€
    web_base = "/uploads/cropped"
    for c in crops:
        c["web_path"] = f"{web_base}/{c['path']}"

    return {
        "type": inv,
        "num":  fields.get("num", ""),
        "date": fields.get("date", ""),
        "sun":  fields.get("sun", ""),
        "cash": fields.get("cash", ""),
        "crops": crops,
    }


def visualize_yolo_results(model, img_path: str, save_path: str = "debug.jpg"):
    import cv2
    results = model(img_path)  # YOLO é æ¸¬
    
    # âœ… Debug è¼¸å‡º YOLO åµæ¸¬æ¡†
    print("\n[YOLO DEBUG]")
    for *xyxy, conf, cls in results.xyxy[0]:
        x1, y1, x2, y2 = map(int, xyxy)
        print(f"  Class={int(cls)} Conf={conf:.2f} BBox=({x1},{y1},{x2},{y2})")
    img = cv2.imread(img_path)
    for *xyxy, conf, cls in results.xyxy[0]:
        x1, y1, x2, y2 = map(int, xyxy)
        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)
        cv2.putText(img, f"{int(cls)} {conf:.2f}", (x1, y1-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
    cv2.imwrite(save_path, img)
    return save_path